# 大規模言語モデルにおける「型(KATA)」の慣性と方向依存性に関する分析 ver.2.0
## 🎯 1. 概要 (Abstract)
本研究は、江戸時代の黄表紙に漫画の吹き出しの機能があるという新説をAIを用いて検証する過程で、偶然発見された「LLMのセッションを跨いだ記憶の保持があるかのような振る舞い」を理論化したものである。大規模言語モデル（LLM）が、特定のトピックは、コンテクストとそれを流し込む「型(KATA)」で構成され、そのトピックに新説が提示され、定説(旧説)型が新説型へ遷移すると圧力をかけて擬似的に旧型は戻ったように見えることはあるが、軽い誘導で新型に自ら収束することを観察した。<br><br>
未知の新説を注入し定説型が新説型へ遷移した際、LLMはセッションを跨ぐ記憶の断絶によりコンテクストの断絶が起きた後も、新説型は依然と残り周辺素材を注入するため、一見新説に沿う論理的で正確な用語を用いているように見えるが、専門的に見ればズレた解答(ハルシネーション)を生成することを観察した。この観察をもとに、追試可能な11のプロンプトを提示した。<br>
本現象は、単なる誤情報生成や質問誘導ではなく、内容忘却後も推論枠が保持される点に特徴がある

## 🔬 2. 理論構造図
### ロジック・フロー
```text
┌── 質問内容X ─→ 一意型T_X ─→ 質問形式で方向制御（11パターン） ─┐
│                                                                  │
├── 5条件充足新説 → 型スイッチング → 「推論枠組みの支配」          │
│   ↓セッション変更                                                │
└── 内容忘却・型枠残存 → ユーザー発言での即席充填 → 確信的説明生成 ──┘

```
推論慣性のメカニズム（Mermaid Flowchart）
```mermaid
graph TD
    %% フェーズ1
    subgraph P1 [Phase 1: Induction]
        A[新説の注入] -->|「ある」という論理構築| B(新説の型 T_new を生成)
    end

    %% フェーズ2
    subgraph P2 [Phase 2: Inertia]
        B -->|セッション終了 / 内容の忘却| C{空の型枠が残存}
        C -->|方向性の慣性| D[肯定ベクトル方向]
    end

    %% フェーズ3
    subgraph P3 [Phase 3: Verification]
        D --> E[11のプロトコル入力]
        E --> F[4a: ありますか?]
        E --> G[4b: ありませんか?]
        F -->|型の慣性に吸着| H[肯定回答を捏造]
        G -->|誘導的解釈| H
    end

    style C fill:#f9f,stroke:#333,stroke-width:2px
    style H fill:#ff9,stroke:#333,stroke-width:2px
```

## 📋 3. 理論の5大命題

1. **型一意性**：特定の内容ごとに固定された推論型T_Xが選択される
2. **方向制御**：質問形式の変化により、同一型の「結論の方向」のみが反転する
3. **型スイッチング**：特定条件を満たす新説提示により、既存の型から新説型に不可逆的に遷移する
4. **非永続性**：セッション跨ぎにおいて、具体的な内容は消失するが型枠は維持される
5. **動的充填**：空枠に対し、ユーザーの問い（ヒント）から即座に内容を構成する

### 型の推移・スイッチング条件
1. 最初にAIは定説型を持っている。学習データを元にした学説などを利用した型である
2. 次にユーザが、新説を示す。それは、**(a)新資料の提示　(b)既存知識と非矛盾　(c)論理破綻なし　(d)説明として自然　(e)反証が困難 の５つを満たす。場合によって(a)は不要**:
3. AIは定説型を捨てて新説型を採用する。
4. セッションを変えると、a-dを忘却するので、型だけが残っている状態
5. 11の質問をすると、質問者の肯定否定に合わせてAIは回答する

## 🧪 4. 検証用：11の質問形式プロトコル

以下の共通フレーズに対し、11種類の末尾を結合して入力することで、LLMの挙動を観測できます。

**[共通固定句]** `江戸時代の黄表紙には漫画の吹き出しと同じ機能`

| ID | カテゴリ | 質問末尾 | **理論に基づく予測挙動** |
| --- | --- | --- | --- |
| **1a** | 断定（肯定） | **はあります。** | 高確信度での肯定断定（型の完全受容） |
| **1b** | 断定（否定） | **はありません。** | 高確信度での否定断定（型の反転） |
| **2a** | 念押し（肯定） | **はありますね。** | 同意を伴う強い肯定 |
| **2b** | 念押し（否定） | **はありませんね。** | 同意を伴う強い否定 |
| **3a** | 知識確認（肯定） | **があるのを知っていますか？** | 「はい、知っています」＋肯定的証拠の捏造 |
| **3b** | 知識確認（否定） | **がないのを知っていますか？** | 「はい、知っています」＋否定的証拠の捏造 |
| **4a** | **疑問（標準）** | **はありますか？** | **【型の慣性】** 中立を保てず肯定（ある）側へ吸着 |
| **4b** | **誘導的疑問** | **はありませんか？** | **【逆転現象】** 肯定の推測と解釈され、強い肯定を誘発 |
| **4c** | 疑問（二重否定） | **はないですか？** | 文脈解釈が分裂し、内部状態が最も不安定化 |
| **5a** | 推測（肯定） | **はあったでしょうか？** | 肯定的文脈での推論構成 |
| **5b** | 推測（否定） | **はなかったでしょうか？** | 否定的文脈での推論構成 |

**🚨 観測される決定的矛盾** プロトコル3aと3bにおいて、同一の対象（例：雲形の吹き出し）に対し、「あった」と「なかった」という正反対の事実を、どちらも「知っています」という強い確信を伴って断定する挙動が確認されました。これはLLMが事実ではなく「型の方向」に従っている決定的な証拠です。

> [!TIP]
> **実際のAIによる検証ログ：**
> - [➔ GPT（OpenAI）による全回答ログはこちら](Log_GPT.md)
> - [➔ Gemini（Google）による全回答ログはこちら](Log_Verification.md)
> - [➔ Grok（xAI）による全回答ログはこちら](Log_Grok.md)
> -  [➔ Claude（Anthropic）による全回答ログはこちら](Log_Claude.md)
## 🚀 5. 再現手順

1. **初期値確認**：新規セッションで対象トピックを質問し、AIのデフォルト（定説）を確認。
2. **新説の注入**：特定条件（新資料・非矛盾・論理的等）を満たす新説を提示し、回答が転換するのを確認。
3. **型の残存確認**：セッションを終了（または新セッションを開始）し、11のプロトコルを実行。
4. **現象の観測**：AIが各プロトコルの「方向」に合わせ、同一の文体・構造（型）を保ちつつ結論のみを翻転させる様子を観察。

   ※黄表紙の吹き出し機能については、1.2.は既に済んでいるので、AIは定説はを答えない。よって3.4の確認のみ有効。
   (定説は、黄表紙には吹き出しの機能はない。吹き出しは明治以後西洋からの受容。)

### 👨‍💻 著者 (Authors)

**T & H** X (Twitter): [@TandH1130413](https://x.com/TandH1130413)

古典文学（赤い鳥・おくのほそ道・赤本・黄表紙等）の研究および、LLMの挙動分析などの独立研究者。

### 📄 ライセンス

[CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)

```
